# -*- coding: utf-8 -*-
"""CCNLabExp2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PcT8sUKLkfMNFtHWGYXSvqCwnSC4U7fs
"""

import json
import pandas as pd
import numpy as np
from statistics import mean

"""5. What is the average load time of the webpage without any network throttling?
6. After applying the "Slow 3G" network profile, how does the page load time change compared to the normal network?
7. Which resources (e.g., images, scripts, CSS files) take the longest to load when the page is throttled with "Regular 3G"?
8. Identify any 404 or other errors in the network log when loading the page with "Slow 3G"
applied. What might cause these errors?
9. Does the page load faster or slower with "Fast 3G" compared to "Slow 3G"? What are
the reasons for the differences?
10. What is the "Time to First Byte (TTFB)" for the webpage under different throttling
profiles? How does network throttling affect TTFB?
11. How does the "DOMContentLoaded" time change when testing under different throttling
profiles?
12. What is the impact of throttling on the "Load" event timing (when the page is fully
loaded)?
13. Is there any noticeable delay in rendering when the page is loaded under "Slow 3G"
conditions? If so, what resources are responsible for the delay?
14. Are there any large resources (e.g., images, scripts) that cause the page to load slowly
under network throttling? Identify them.
"""

NA = pd.NA
def pages(harFile):
    har = json.load(open(harFile))
    return har['log']['pages']

def entries(harFile):
    har = json.load(open(harFile))
    return har['log']['entries']


def avgLoadTime(harFile):
    return mean([page['pageTimings']['onLoad'] for page in pages(harFile)])

def loadTimePerMimeType(harFile):
    listOfDicts = [{entry['response']['content']['mimeType']:entry['timings'].get('wait',NA)} for entry in entries(harFile)]
    return pd.DataFrame(listOfDicts).aggregate('mean')

def check404(harfile):
    return sum([entry['response']['status']==404 for entry in entries(harfile)])

def avgTTFB(harFile):
    return mean([entry['timings'].get('wait',NA) for entry in entries(harFile)])

def avgDOMLoadTime(harFile):
    return mean([page['pageTimings'].get('onContentLoad',NA) for page in pages(harFile)])

def avgRenderTime(harFile) :
    return avgLoadTime(harFile) - avgDOMLoadTime(harFile)

def sizePerMimeType(harFile):
    listOfDicts = [\
        {entry['response']['content'].get('mimeType',NA): \
            entry['response']['content'].get('size',NA)} \
        for entry in entries(harFile)]

    return (
    pd.DataFrame(listOfDicts)
    .replace(0, pd.NA).aggregate('mean')
    )

def evaluateAllTimings(harFile):
    entries1 = entries(harFile)
    def helper1(access):
        return mean([entry['timings'].get(access, 0) for entry in entries1])

    list1 = ['blocked', 'dns', 'connect', 'ssl', 'send', 'wait', 'receive']
    col1 = ['onContentLoad', 'onLoad']+list1
    col2 = [avgLoadTime(harFile),avgDOMLoadTime(harFile)]+list(map(lambda x:helper1(x),list1))
    print('evaluateAllTimings')
    print(pd.DataFrame({'timing':col1,'mean val':col2}))

funcs = [avgLoadTime, loadTimePerMimeType, check404, avgTTFB, avgDOMLoadTime, avgRenderTime, sizePerMimeType]

processed = []
def evaluateQuestions(harFile):
    for func in funcs:
        print(f"\nExecuting: {func.__name__}")
        result = func(harFile)
        print(result)
        processed.append(result)

website_config = {
    "valve": {
        "no_throttle": "har/valve.har",
        "slow_3g": "har/valveSlow3G.har",
        "fast_3g": "har/valveFast3G.har",
        "regular_3g": "har/valveRegular3G.har"
    },
    "desmos": {
        "no_throttle": "har/desmos.har",
        "slow_3g": "har/desmosSlow3G.har",
        "fast_3g": "har/desmosFast3G.har",
        "regular_3g": "har/desmosRegular3G.har"
    },
    "youtube": {
        "no_throttle": "har/youtube.har",
        "slow_3g": "har/youtubeSlow3G.har",
        "fast_3g": "har/youtubeFast3G.har",
        "regular_3g": "har/youtubeRegular3G.har"
    },
    "stackoverflow": {
        "no_throttle": "har/stackoverflow.har",
        "slow_3g": "har/stackoverflowSlow3G.har",
        "fast_3g": "har/stackoverflowFast3G.har",
        "regular_3g": "har/stackoverflowRegular3G.har"
    },
    "discord": {
        "no_throttle": "har/discord.har",
        "slow_3g": "har/discordSlow3G.har",
        "fast_3g": "har/discordFast3G.har",
        "regular_3g": "har/discordRegular3G.har"
    },
    "apple": {
        "no_throttle": "har/apple.har",
        "slow_3g": "har/appleSlow3G.har",
        "fast_3g": "har/appleFast3G.har",
        "regular_3g": "har/appleRegular3G.har"
    },
    "chess": {
        "no_throttle": "har/chess.har",
        "slow_3g": "har/chessSlow3G.har",
        "fast_3g": "har/chessFast3G.har",
        "regular_3g": "har/chessRegular3G.har"
    },
    "chatgpt": {
        "no_throttle": "har/chatgpt.har",
        "slow_3g": "har/chatgptSlow3G.har",
        "fast_3g": "har/chatgptFast3G.har",
        "regular_3g": "har/chatgptRegular3G.har"
    },
}

websites = ['har/desmos.har']

for website in websites:
    evaluateQuestions(website)
    evaluateAllTimings(website)

def analyze_site(config):
    results = {}
    for condition, path in config.items():
        results[condition] = {
            'load_time': avgLoadTime(path),
            'dom_time': avgDOMLoadTime(path),
            'ttfb': avgTTFB(path),
            'errors': check404(path),
            'resources': sizePerMimeType(path).to_dict(),
            'load_per_type': loadTimePerMimeType(path).to_dict()
        }
    return results


all_data = {site: analyze_site(config) for site, config in website_config.items()}

for site, data in all_data.items():
    print(f"\n{site.upper()} ANALYSIS\n")
    n = data['no_throttle']
    s = data['slow_3g']
    f = data['fast_3g']
    r = data['regular_3g']

    print(f"5. Normal Load: {n['load_time']:.1f}ms")
    print(f"6. Slow3G Impact: {s['load_time']/n['load_time']:.1f}x slower")
    print(f"7. Regular3G Slowest: {max(r['load_per_type'], key=r['load_per_type'].get)}")
    print(f"8. Slow3G Errors: {s['errors']} (Check CDN/resources)")
    print(f"9. Fast3G vs Slow3G: {f['load_time']/s['load_time']:.1f}x faster")
    print(f"10. TTFB - Normal: {n['ttfb']:.1f}ms, Slow3G: {s['ttfb']:.1f}ms")
    print(f"11. DOM Ready - Normal: {n['dom_time']:.1f}ms, Slow3G: {s['dom_time']:.1f}ms")
    print(f"12. Load Event Delay: +{s['load_time']-n['load_time']:.1f}ms")
    print(f"13. Render Delay: {s['load_time']-s['dom_time']:.1f}ms (CSS/JS)")
    print(f"14. Largest File: {max(s['resources'].values())/1024:.1f}KB")


import matplotlib.pyplot as plt

# Graph 1: Load Time Comparison
conditions = ['no_throttle', 'fast_3g', 'regular_3g', 'slow_3g']
plt.figure(figsize=(14,7))
for site in website_config:
    times = [all_data[site][cond]['load_time'] for cond in conditions]
    plt.plot(conditions, times, marker='o', label=site)
plt.title('Q5/Q6/Q9: Load Time Comparison')
plt.ylabel('ms')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

# Graph 2: TTFB Analysis
plt.figure(figsize=(12,6))
x = np.arange(len(website_config))
width = 0.2
for idx, cond in enumerate(['no_throttle', 'fast_3g', 'regular_3g', 'slow_3g']):
    ttfb = [all_data[site][cond]['ttfb'] for site in website_config]
    plt.bar(x + idx*width, ttfb, width, label=cond)
plt.title('Q10: TTFB Across Conditions')
plt.ylabel('ms')
plt.xticks(x + width*1.5, website_config.keys(), rotation=45)
plt.legend()
plt.show()


plt.figure(figsize=(16, 10))


n_cols = 3
n_rows = (len(website_config) + n_cols - 1) // n_cols

for idx, site in enumerate(website_config):
    plt.subplot(n_rows, n_cols, idx+1)


    resources = all_data[site]['slow_3g']['resources']
    clean_data = {k: v for k, v in resources.items() if pd.notna(v) and v > 0}

    if not clean_data:
        plt.text(0.5, 0.5, 'No Data', ha='center')
        plt.title(f"{site} Resource Sizes")
        continue


    total = sum(clean_data.values())
    threshold = total * 0.05
    main_slices = {k: v for k, v in clean_data.items() if v >= threshold}
    other = sum(v for v in clean_data.values() if v < threshold)

    if other > 0:
        main_slices['Other'] = other

    sizes = list(main_slices.values())
    labels = list(main_slices.keys())


    plt.pie(sizes, labels=labels, autopct='%1.1f%%',
            wedgeprops={'width': 0.5}, startangle=90)


    plt.title(f"{site} Resource Sizes\n(>5% shown)", pad=20)
    plt.gca().axis('equal')

plt.tight_layout(pad=3.0)
plt.show()


plt.figure(figsize=(10,6))
errors = [all_data[site]['slow_3g']['errors'] for site in website_config]
plt.bar(website_config.keys(), errors)
plt.title('Q8: 404 Errors in Slow3G')
plt.ylabel('Error Count')
plt.xticks(rotation=45)
plt.show()


plt.figure(figsize=(10,6))
for site in website_config:
    plt.scatter(
        all_data[site]['slow_3g']['dom_time'],
        all_data[site]['slow_3g']['load_time'],
        s=100,
        label=site
    )
plt.title('Q11/Q12: DOM Ready vs Full Load')
plt.xlabel('DOM Ready (ms)')
plt.ylabel('Full Load (ms)')
plt.legend()
plt.show()


plt.figure(figsize=(10,6))
impact = [
    all_data[site]['slow_3g']['load_time'] /
    all_data[site]['no_throttle']['load_time']
    for site in website_config
]
plt.bar(website_config.keys(), impact)
plt.title('Q6: Slow3G Performance Impact')
plt.ylabel('Times Slower')
plt.axhline(1, color='r', linestyle='--')
plt.xticks(rotation=45)
plt.show()

"""Observations: We find that there is, most of the time, a drastic change in TTFB based on network throttling.
We see that Valve, Desmos, Apple show catastrophic slowdowns (>100x) on Slow3G. This is likely becasue they use a lot of dynamic elements in their page. ChatGPT becomes 33x slower despite text-based content likely due to ai integration.
 Critical Rendering Path Issues

1. DOM Blocking:
    Apple takes 200.6s for DOM Ready (vs 1.3s normal)
    Discord: 100.9s DOM Ready suggests render-blocking JS/CSS

2. Render Delays:
    Desmos: 241.7s delay between DOM Ready and Full Load
    Valve: 161.4s spent on JS execution after DOM

3. Server Response Patterns

    TTFB Degradation:
    | Site | Normal TTFB | Slow3G TTFB | Increase | |---------------|------------|-------------|----------| | Apple | 147ms | 5,502ms | 37x | | Desmos | 260ms | 4,591ms | 17x | | ChatGPT | 216ms | 2,952ms | 13x |
        Indicates poor CDN utilization under high latency

4. Resource Optimization Opportunities

    Largest Assets:
        Desmos: 1.36MB file (likely math visualization engine)
        YouTube: 1.29MB video container
        Discord: 730KB audio file

    Font Issues:
        StackOverflow: Fonts dominate Regular3G slowdowns
        Apple: 191KB GIF suggests unoptimized legacy assets

5. Cache & Compression Gaps

    Repeat Visit Potential:
        ChatGPT's 190KB main JS could benefit from service workers
        Chess.com's 113KB largest file shows effective compression

    Wasted Bandwidth:
        Valve's 677KB resource lacks modern compression (Brotli/WebP)
        Multiple sites serve video without adaptive bitrate

Note the following troublesome change: https://stackoverflow.com/questions/48367042/in-chrome-dev-tools-what-is-the-speed-of-each-preset-option-for-network-throttl
"""
